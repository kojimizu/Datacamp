---
title: "Dealing with Missing Data"
author: "Koji Mizumura"
date: "2019-4-1 - `r Sys.Date()`"
output: 
  word_document:
    toc: yes
    toc_depth: '4'
  # html_document:
  #   number_sections: yes
  #   section_divs: yes
  #   theme: readable
  #   toc: yes
  #   toc_depth: 4
  #   toc_float: yes
  github_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  fig.height = 4.5,
  error = FALSE,
  message = FALSE, 
  warning = FALSE, 
  collapse = TRUE,
  cache = TRUE
)
```

# Why care about missing data (NA)


```{r}
library(tidyverse)
library(magrittr)
```

## Introduction

- working with real-world data = working with missing data
- Missing data can have unexpected effects on the analysis
- Bad imputation can lead to poor estimates and decisions

We will learn;

- What missing values are
- How to find missing data
- How to wrangle and tidy missing data
- Explore why is data missing


The definition is 

> missing values are values that should have been recored but were not.

```{r eval=FALSE}
x <- c(1,NA,3,NA,NA,5)

any_na(x)
are_na(x)
n_miss(x)
prop_miss(x)
```

## Using and finding missing values
When working with missing data, there are a couple of commands that you should be familiar with - firstly, you should be able to identify if there are any missing values, and where these are.

Using the `any_na()` and `are_na()` tools, identify which values are missing.

```{r eval=FALSE}
# Create x, a vector, with values NA, NaN, Inf, ".", and "missing"
x <- c(NA, NaN, Inf, ".", "missing")

library(rlang)
library(Kmisc)


# Use any_na() and are_na() on to explore the missings
any_na(x)
are_na(x)
```


## How many missing values are there?

One of the first things that you will want to check with a new dataset is if there are any missing missing values, and how many there are.

You could use `are_na()` to and count up the missing values, but the most efficient way to count missings is to use the `n_miss()` function. This will tell you the total number of missing values in the data.

You can then find the percent of missing values in the data with the pct_miss function. This will tell you the percentage of missing values in the data.

```{r eval=FALSE}
# Use n_miss() to count the total number of missing values in dat_hw

head(dat_hw)
n_miss(dat_hw)

# Use n_miss() on dat_hw$weight to count the total number of missing values
n_miss(dat_hw$weight)

# Use n_complete() on dat_hw to count the total number of complete values
n_complete(dat_hw)

# Use n_complete() on dat_hw$weight to count the total number of complete values
n_complete(dat_hw$weight)

# Use prop_miss() and prop_complete() on dat_hw to count the total number of missing values in each of the variables
prop_miss(dat_hw)
prop_complete(dat_hw)
```

## Working with missing values

R stores missing values as NA, which have some special behavior. Now that you can define missing data and understand how R stores missing values, can you predict what will happen when we operate with some missing values?

What is the output of the following four commands in R? Try them out in the code console to test them before you submit your answer.

## Why care about missing values?

Two summaries
1. Basic summaries of missingness: `n_miss`, `n_complete`
2. Dataframe summaries of missingness: `miss_var_summary`, `miss_case_summary`

These functions work with `group_by`, dplyr functions.

## Summarizing missingness
Now that you understand the behavior of missing values in R, and how to count them, let's scale up our summaries for cases (rows) and variables, using `miss_var_summary()` and `miss_case_summary()`, and also explore how they can be applied for groups in a dataframe, using the group_by function from dplyr.

```{r}
# Summarise missingness in each variable of the `airquality` dataset
library(naniar)
miss_var_summary(airquality)

# Summarise missingness in each case of the `airquality` dataset
miss_case_summary(airquality)

# Return the summary of missingness in each variable, grouped by Month, in the `airquality` dataset
airquality %>% dplyr::group_by(Month) %>% miss_var_summary()

# Return the summary of missingness in each case, grouped by Month, in the `airquality` dataset
airquality %>% dplyr::group_by(Month) %>% miss_case_summary()
```

## Tabulating Missingness
The summaries of missingness we just calculated give us the number and percentage of missing observations for the cases and variables.

Another way to summarise missingness is by tabulating the number of times that there are 0, 1, 2, 3, missings in a variable, or in a case.

In this exercise we are going to tabulate the number of missings in each case and variable using `miss_var_table()` and `miss_case_table()`, and also combine these summaries with the the `group_by` operator from `dplyr`. to explore the summaries over a grouping variable in the dataset.

```{r}
# Tabulate missingness in each variable and case of the `airquality` dataset
miss_var_table(airquality)
miss_case_table(airquality)

# Tabulate the missingness in each variable, grouped by Month, in the `airquality` dataset
library(dplyr)
airquality %>% group_by(Month) %>% miss_var_table()

# Tabulate of missingness in each case, grouped by Month, in the `airquality` dataset
airquality %>% group_by(Month) %>% miss_case_table()
```

## Other summaries of missingness

Some summaries of missingness are particularly useful for different types of data. For example, miss_var_span() and miss_var_run().

- `miss_var_span()` calculates the number of missing values in a specified variable for a repeating span. This is really useful in time series data, to look for weekly (7 day) patterns of missingness

- `miss_var_run()` calculates the number of "runs" or "streaks" of missingness. This is useful to find unusual patterns of missingness, for example, you might find a repeating pattern of 5 complete and 5 missings.

Both `miss_var_span()` and `miss_var_run()` work with the `group_by` operator from dplyr.

```{r}
# Calculate the summaries for each run of missingness for the variable, hourly_counts
pedestrian %>% colnames()
miss_var_run(pedestrian, var = hourly_counts)

# Calculate the summaries for each span of missingness, for a span of 4000, for the variable hourly_counts
miss_var_span(pedestrian, var = hourly_counts, span_every = 4000)

# For each `month` variable, calculate the run of missingness for hourly_counts
pedestrian %>% group_by(month) %>% miss_var_run(var = hourly_counts)

# For each `month` variable, calculate the span of missingness of a span of 2000, for the variable hourly_counts
pedestrian %>% group_by(month) %>% miss_var_span(var = hourly_counts, span_every = 2000)
```

## how do we visualize missing values?

Built-in visualization in `naniar` package.

We will cover:
- How to get a bird's eye view of the data
- How to look at missings in the variable and cases
- How to generate visualizations for missing spans and across groups in thd data


```{r}
naniar::vis_miss(airquality)

# actiate clustering
naniar::vis_miss(airquality, cluster = T)
```

When we want to look at missings in variables and cases.
```{r}
library(naniar)
gg_miss_var(airquality)
gg_miss_case(airquality)
```

`gg_miss_var` and `gg_miss_case` can be used for faceting together.

```{r}
gg_miss_var(airquality, facet = Month)
```

With combination, we can use `gg_miss_upset`
```{r}
library(UpSetR)

airquality %>% 
  as_shadow_upset() %>% 
  upset()

# gg_miss_upset(airquality)
```

```{r}
gg_miss_fct(x = airquality, fct = Month)
```

```{r}
gg_miss_span(pedestrian, hourly_counts,
             span_every = 3000)
```

## Your first missing data visualizations

It can be difficult to get a handle on where the missing values are in your data, and here is where visualization can really help.

The function `vis_miss()` creates an overview visualization of the missingness in the data. It also has options to cluster rows based on missingness, using `cluster = TRUE`; as well as options for sorting the columns, from most missing to least missing (`sort_miss = TRUE`).

```{r}
# Visualize all of the missingness in the `riskfactors`  dataset
vis_miss(riskfactors)

# Visualize and cluster all of the missingness in the `riskfactors` dataset
vis_miss(riskfactors, cluster = TRUE)

# visualise and sort the columns by missingness in the `riskfactors` dataset
vis_miss(riskfactors, sort_miss = TRUE)
```

## Visualizing missing cases and variables

To get a clear picture of the missingness across variables and cases, use `gg_miss_var()` and `gg_miss_case()`. These are the visual counterpart to `miss_var_summary()` and `miss_case_summary()`.

These can be split up into multiple plots with one for each category by choosing a variable to facet by.

```{r}
# Visualize the number of missings in cases using `gg_miss_case()`
gg_miss_case(riskfactors)

# Explore the number of missings in cases using `gg_miss_case()` and facet by the variable `education`
gg_miss_case(riskfactors, facet = education)

# Visualize the number of missings in variables using `gg_miss_var()`
gg_miss_var(riskfactors)

# Explore the number of missings in variables using `gg_miss_var()` and facet by the variable `education`
gg_miss_var(riskfactors, facet = education)
```

## Visualizing missingess patterns

Let's practice a few different ways to visualize patterns of missingness using:

- `gg_miss_upset()` to give an overall pattern of missingness.
- `gg_miss_fct()` for a dataset that has a factor of interest: marriage.
- and `gg_miss_span()` to explore the missingness in a time series dataset.

```{r}
# Using the airquality dataset, explore the missingness pattern using gg_miss_upset()
library(naniar)
gg_miss_upset(airquality)

# With the riskfactors dataset, explore how the missingness changes across the marital variable using gg_miss_fct()
gg_miss_fct(x = riskfactors, fct = marital)

# Using the pedestrian dataset, explore how the missingness of hourly_counts changes over a span of 3000 
gg_miss_span(pedestrian, var = hourly_counts, span_every = 3000)

# Using the pedestrian dataset, explore the impact of month by facetting by month
# and explore how missingness changes for a span of 1000
gg_miss_span(pedestrian, var = hourly_counts , span_every = 1000, facet = month)
```

# Wrangling and tidying up missing values

## Searching for and replacing missing values

- How to look for hidden missing values
- Replacing missing value labels with `NA`
- Checking your assumptions on missingness

To search for and replace missing values

The idea is NA, however, it can be coded incorrectly (e.g., "missing" etc.). 

```{r}
chaos <- tibble::tribble(
  ~ score, ~ grade, ~ place,
  3, "N/A", -99,
  -99, "E", 97,
  4, "missing", 95,
  -99, "na", 92,
  7, "n/a", -98,
  1, " ", "missing",
  12, ".", 88,
  16, " ", ".",
  9, "N/a", 86
)

chaos
```

```{r miss_scan_count}
chaos %>% 
  miss_scan_count(search = list("N/A", "N/a"))
```

```{r miss_replace}

chaos %>% 
  replace_with_na(
    replace = list(grade = c("N/A", "N/a"))
  )
```

### Scoped variances of `replace_with_na` 

`replace_with_na` can be repetitive:

- Use it across many different variables and values
- Complex cases, replacing values less than -1, only affect character columns.

Thus, there are other functions
1. `replace_with_na_all()`: All variables
2. `replace_with_na_at()`: A subset of selected viriables.
3. `replace_with_na_if()`: A subset of variables that fullfill some conditions (numeric, character)

```{r}
chaos %>% 
  replace_with_na_all(condition = ~.x==-99)

chaos %>% 
  replace_with_na_all(condition =  ~ .x %in% c("N/A", "missing", "na"))
```

## Using `miss_scan_count()`

You have a dataset with missing values coded as `"N/A"`, `"missing"`, and `"na"`. But before we go ahead and start replacing these with `NA`, we should get an idea of how big the problem is.

Use `miss_scan_count` to count the possible missings in the dataset, `pacman`, a dataset of pacman scores, containing three columns:

- `year`: the year that person made that score.
- `initial`: the initials of the person.
- `score`: the scores of that person.


```{r eval=FALSE}
library(pacman)

# Explore the strange missing values "N/A"
miss_scan_count(data = pacman, search = list("N/A"))

# Explore the strange missing values "missing"
miss_scan_count(data = pacman, search = list("missing"))

# Explore the strange missing values "na"
miss_scan_count(data = pacman, search = list("na"))

# Explore the strange missing values " " (a single space)
miss_scan_count(data = pacman, search = list(" "))

# Explore all of the strange missing values, "N/A", "missing", "na", " "
miss_scan_count(data = pacman, search = list("N/A", "missing", "na", " "))
```

## Using `replace_with_na`

Following on from the previous dataset, we now know that we have a few strange missing values.

Now, we are going to do something about it, and replace these values with missings (e.g. `NA`) using the function `replace_with_na()`.

```{r eval=FALSE}
# Print the top of the pacman data using `head()`
head(pacman)

# Replace the strange missing values "N/A", "na", and "missing" with `NA` for the variables, year, and score
pacman_clean <- replace_with_na(pacman, replace = list(year = c("N/A", "na", "missing"),
                                score = c("N/A", "na", "missing")))
                                        
# Test if `pacman_clean` still has these values in it?
miss_scan_count(pacman_clean, search = list("N/A", "na", "missing"))
```

## Using replace_with_na scoped variants

To reduce code repetition when replacing values with `NA`, use the "scoped vatriants" of `replace_with_na()`:

- `replace_with_na_at()`
- `replace_with_na_if()`
- `replace_with_na_all()`

The syntax of replacement looks like this:

```{r eval=FALSE}
~.x == "N/A"
```

This replaces all cases that are equal to "N/A".

```{r eval=FALSE}
~.x %in% c("N/A", "missing", "na", " ")
```

Replaces all cases that have "N/A", "missing", "na", or " ".

```{r eval=FALSE}
# Use `replace_with_na_at()` to replace with NA
replace_with_na_at(pacman,
                   .vars = c("year", "month", "day"), 
                   ~.x %in% c("N/A", "missing", "na", " "))

# Use `replace_with_na_if()` to replace with NA the character values using `is.character`
replace_with_na_if(pacman,
                   .predicate = is.character, 
                   ~.x %in% c("N/A", "missing", "na", " "))

# Use `replace_with_na_all()` to replace with NA
replace_with_na_all(pacman, ~.x %in% c("N/A", "missing", "na", " "))
```

## Filling down missing values

How to handle implicit missing values.

Perspective on missing data,

- Explicitly: They are missing with `NA`
- Implicitly: Not shown in the data, but implied

We will use `tidyr::complete` for checking implicit missingness.

```{r eval=FALSE}
tetris %>% 
  tidyr::complete(name, time)
```

Sometimes, the `tidyr::fill` is useful for filling data. But, the warning is that it only solves only a few missing data problems.

## Fix implicit missings using `complete()`

We are going to explore a new dataset, `frogger`.

This dataset contains 4 scores per player recorded at different times:

- `morning`
- `afternoon`
- `evening`
- `late_night`

Every player should have played 4 games, one at each of these times, but it looks like not every player completed all of these games.

Use the `complete()` function to make these implicit missing values explicit

```{r eval=FALSE}
# Print the frogger data to have a look at it
frogger

# Use `complete()` on the `time` variable to make implicit missing values explicit
frogger_tidy <- frogger %>% complete(name, time)
```

## Fix explicit missings using `fill()`

One type of missing value that can be obvious to deal with is where the first entry of a group is where the first entry of a group is given, but subsequent entries are marked `NA`.

These missing values often result from empty values in spreadsheets to avoid entering multiple names multiple times; as well as for "human readability".

This type of problem can be solved by using the `fill()` function. from the `tidyr` package.

```{r eval=FALSE}
# Print the frogger data to have a look at it
frogger

# Use `fill()` to fill down the name variable in the frogger dataset
frogger %>% fill(name)
```

## Using `complete()` and `fill()` together

Use `complete()` and `fill()` together to fix explicit and implicitly missing values in the frogger dataset.

```{r eval=FALSE}
# Print the frogger data to have a look at it
frogger

# Correctly fill() and complete() missing values so that our dataset becomes sensible

frogger %>% 
  fill(name) %>%
  complete(name, time)
```


## Missing data dependence

- __MCAR__: missing completely at random
- __MAR__: missing at random
- __MNAR__: Missing not at random

MCAR, missingness has no association with any data you have observed, or not observed.

For __MCAR__, the imputation is advisable. Deleting observation may reduce sample size, limiting inference, but will not bias.

MAR, missing depends on data observed, but not data observed.

For __MAR__, the imputation is recommended, delteting observaion is not ideal, as it may lead to bias.

 MNAR, missingness of the reponse is related to an unobserved value relevant to the asessment of interest. 
 
 For __MNAR__, data will be biased from deletion and imoutation, inference can be limited, proceed with caution.
 
## Exploring missingness dependence
To learn about the structure of the missingness in data, you can explore how sorting changes how missingness is presented.

For the `oceanbuoys` dataset, explore the missingness with `vis_miss()`, and then arrange by a few different variables

This is not a definitive process, but it will get you started to ask the right questions of your data. We explore more powerful techniques in the next chapter.

```{r}
# naniar::vis_miss()
# Arrange by year
oceanbuoys %>% arrange(year) %>% vis_miss()

# Arrange by latitude
oceanbuoys %>% arrange(latitude) %>% vis_miss()

# Arrange by wind_ew (wind east west)
oceanbuoys %>% arrange(wind_ew) %>% vis_miss()
```

## Further exploring missingeness dependence

Using the information from earlier on the oceanbuoys dataset, which of these statements makes the most appropriate statement on the missingness type?

Try using gg_miss_var(), and gg_miss_case(), facetting by year to get more information. For example:

```{r}
library(naniar)
gg_miss_var(oceanbuoys, facet = year)
```

# Testing missing relationships
## Missing data workflows: the shadow matrix and nabular data

Census data containing, `income` and `education`

Shadow matrix is a clear representation of binary form of data(`0`, `1` or `!NA` or `NA`). The two main features are

1. Coordinated names
2. Clear values

Nabular data can be used instead of shadow matrix (The nabular data include both NA and original data input). The nabular data can be created by `bind_shadow`.

## Creating shadow matrix data

Missing data can be tricky to think about, as they don't usually proclaim themselves for you, and instead hide amongst the weeds of the data.

One way to help expose missing values is to change the way we think about the data - by thinking about every single data value being missing or not missing.

The `as_shadow()` function in R transforms a dataframe into a shadow matrix, a special data format where the values are either missing (`NA`), or Not Missing (`!NA`).

```{r}
# Create shadow matrix data with `as_shadow()`
as_shadow(oceanbuoys)

# Create nabular data by binding the shadow to the data with `bind_shadow()`
bind_shadow(oceanbuoys)

# Bind only the variables with missing values by using bind_shadow(only_miss = TRUE)
bind_shadow(oceanbuoys, only_miss = TRUE)
```

## Performing grouped summaries of missingness

Now that you can create nabular data, let's use it to explore the data. Let's calculate summary statistics based on the missingness of another variable.

To do this we are going to use the following steps:

- First, `bind_shadow()` turns the data into nabular data.
- Next, perform some summaries on the data using `group_by()` and `summarise()` to calculate the mean and standard deviation, using the `mean()` and `sd()` functions.

```{r}
# `bind_shadow()` and `group_by()` humidity missingness (`humidity_NA`)
oceanbuoys %>%
  bind_shadow() %>%
  group_by(humidity_NA) %>% 
  summarise(wind_ew_mean = mean(wind_ew), # calculate mean of wind_ew
            wind_ew_sd = sd(wind_ew)) # calculate standard deviation of wind_ew
  
# Repeat this, but calculating summaries for wind north south (`wind_ns`).
oceanbuoys %>%
  bind_shadow() %>%
  group_by(humidity_NA) %>%
  summarise(wind_ns_mean = mean(wind_ns),
            wind_ns_sd = sd(wind_ns))
```

## Further exploring more combinations of missingness

It can be useful to get a bit of extra information about the number of cases in each missing condition.

In this exercise, we are going to add information about the number of observed cases using `n()` inside the `summarise()` function.

We will then add an additional level of grouping by looking at the combination of humidity being missing (`humidity_NA`) and sea temperature being missing (`sea_temp_c_NA`).

```{r}
# Summarise wind_ew by the missingness of `air_temp_c_NA`
oceanbuoys %>% 
  bind_shadow() %>%
  group_by(air_temp_c_NA) %>%
  summarise(wind_ew_mean = mean(wind_ew),
            wind_ew_sd = sd(wind_ew),
            n_obs = n())

# Summarise wind_ew by missingness of `air_temp_c_NA` and `humidity_NA`
oceanbuoys %>% 
  bind_shadow() %>%
  group_by(air_temp_c_NA, humidity_NA) %>%
  summarise(wind_ew_mean = mean(wind_ew),
            wind_ew_sd = sd(wind_ew),
            n_obs = n())

```

## Visualizing missingness across one variable

We explore conditional missings with ggplot

- How to use nabular data to explore how values change according to the other values going missing
- Explore visualizations:
  - densities
  - boxplots
  - dofferent methods of splitting the visualization

When we want to visualize missings using densities

```{r}
ggplot(airquality,
       aes(x=Temp))+
  geom_density()

airquality %>% 
  bind_shadow() %>% 
  ggplot(aes(x=Temp, col=Ozone_NA))+
  geom_density()

airquality %>% 
  bind_shadow() %>% 
  ggplot(aes(x=Temp))+
  geom_density()+
  facet_wrap(~Ozone_NA)

airquality %>% 
  bind_shadow() %>% 
  ggplot(aes(x = Temp,
             color = Ozone_NA))+
  geom_density()+
  facet_wrap(~Solar.R_NA)
```

## Nabular data and filling by missingness

Summary statistics are useful to calculate, but as they say, a picture tells you a thousand words.

In this exercise, we are going to explore how you can use `nabular` data to explore the variation in a variable by the missingness of another.

We are going to use the oceanbuoys dataset from `naniar`.

```{r }
# First explore the missingness structure of `oceanbuoys` using `vis_miss()`
vis_miss(oceanbuoys)

# Explore the distribution of `wind_ew` for the missingness of `air_temp_c_NA` using  `geom_density()`
bind_shadow(oceanbuoys) %>%
  ggplot(aes(x = wind_ew, 
             color = air_temp_c_NA)) + 
  geom_density()

# Explore the distribution of sea temperature for the missingness of humidity (humidity_NA) using  `geom_density()`
  bind_shadow(oceanbuoys) %>%
  ggplot(aes(x = sea_temp_c,
             color = humidity_NA)) + 
  geom_density()
```

## Nabular data and summarising by missingness

In this exercise, we are going to explore how to use `nabular` data to explore the variation in a variable by the missingness of another.

We are going to use the `oceanbuoys` dataset from `naniar`

```{r }
# Explore the distribution of wind east west (`wind_ew`) for the missingness of air temperature using  `geom_density()` and facetting by the missingness of air temperature (`air_temp_c_NA`).
oceanbuoys %>%
  bind_shadow() %>%
  ggplot(aes(x = wind_ew)) + 
  geom_density() + 
  facet_wrap(~air_temp_c_NA)

# Build upon this visualisation by filling by the missingness of humidity (`humidity_NA`).
oceanbuoys %>%
  bind_shadow() %>%
  ggplot(aes(x = wind_ew,
             color = humidity_NA)) + 
  geom_density() + 
  facet_wrap(~humidity_NA)
```

## Explore variation by missingness:boxplots

Previous exercises use `nabular` data along with density plots to explore the variation in a variable by the missingness of another.

We are going to use the `oceanbuoys` dataset from `naniar`, using boxplots instead of facets or others to explore different layers of missingness.

```{r }
# Explore the distribution of wind east west (`wind_ew`) for the missingness of air temperature using  `geom_boxplot()`
oceanbuoys %>%
  bind_shadow() %>%
  ggplot(aes(x = air_temp_c_NA,
             y = wind_ew)) + 
  geom_boxplot()

# Build upon this visualisation by facetting by the missingness of humidity (`humidity_NA`).
oceanbuoys %>%
  bind_shadow() %>%
  ggplot(aes(x = air_temp_c_NA,
             y = wind_ew)) + 
  geom_boxplot() + 
  facet_wrap(~humidity_NA)
```


## Visualizing missingenss across two variables

Missing values are typically ignored in the scatterplot. `geom_miss_point` transforms and impute the missing values in the dataset. This is utilized with 
`facet` syntax as well.

```{r }
ggplot(airquality,
       aes(x=Ozone, y = Solar.R))+
  geom_point()

ggplot(airquality,
       aes(x=Ozone, y = Solar.R))+
  geom_miss_point()

airquality %>% 
  bind_shadow() %>% 
  ggplot(aes(x = Wind,
             y = Ozone))+
  geom_miss_point()+
  facet_wrap(~Solar.R_NA)
```

## Exploring missing data with scatterplots

Missing values in a scatterplot in `ggplot2` are removed by default, with a warning.

We can display missing values in a scatterplot, using `geom_miss_point()` - a special `ggplot2` geom that shifts the missing values into the plot, displaying them 10% below the minimum of the variable.

Let's practice using this visualisation with the `oceanbuoys` dataset.

```{r}
# Explore the missingness in wind and air temperature, and display the missingness using `geom_miss_point()`
ggplot(oceanbuoys,
       aes(x = wind_ew,
           y = air_temp_c)) + 
  geom_miss_point()

# Explore the missingness in humidity and air temperature, and display the missingness using `geom_miss_point()`
ggplot(oceanbuoys,
       aes(x = humidity,
           y = air_temp_c)) + 
  geom_miss_point()
```

## Using facets to explore missingness

Because `geom_miss_point()` is a ggplot geom, you can use it with `ggplot2` features like facetting.

This means we can rapidly explore the missingness and stay within the familar bounds of `ggplot2`.

```{r}
# Explore the missingness in wind and air temperature, and display the missingness using `geom_miss_point()`. Facet by year to explore this further.
ggplot(oceanbuoys,
       aes(x = wind_ew,
           y = air_temp_c)) + 
  geom_miss_point() + 
  facet_wrap(~year)

# Explore the missingness in humidity and air temperature, and display the missingness using `geom_miss_point()` Facet by year to explore this further.
ggplot(oceanbuoys,
       aes(x = humidity,
           y = air_temp_c)) + 
  geom_miss_point() + 
  facet_wrap(~year)
```

## Faceting to explore missingness (multiple plots)

Another useful technique with `geommisspoint()` is to explore the missingness by creating multiple plots.

Just as we have done in the previous exercises, we can use the `nabular` data to help us create additional facetted plots.

We can even create multiple facetted plots according to values in the data, such as year, and features of the data, such as missingness.

```{r}
# Use geom_miss_point() and facet_wrap to explore how the missingness in wind_ew and air_temp_c is different for missingness of humidity
bind_shadow(oceanbuoys) %>%
  ggplot(aes(x = wind_ew,
           y = air_temp_c)) + 
  geom_miss_point() + 
  facet_wrap(~humidity_NA)

# Use geom_miss_point() and facet_grid to explore how the missingness in wind_ew and air_temp_c is different for missingness of humidity AND by year - by using `facet_grid(humidity_NA ~ year)`
bind_shadow(oceanbuoys) %>%
  ggplot(aes(x = wind_ew,
             y = air_temp_c)) + 
  geom_miss_point() + 
  facet_grid(humidity_NA~year)
```

# Connecting the dots (Imputation)
## Filling in the blanks

Exloring the missing dat help us to understand the dataset. 
- __Using imputation to understand data structure__
- __Visualizing + Exploring imputed values__

1) Imputing data to explore missingness
2) Track missing values
3) Visualize imputed values against data

```{r}
impute_below(c(5,6,7,NA,9,10))
```

- `impute_below_if()`:

```{r eval=FALSE}
impute_below_if(data, is.numeric)
```

- `impute_below_at()`:

```{r eval=FALSE}
impute_below_at(data, vars(var1, var2))
```

- `impute_below_all`

```{r eval=FALSE}
impute_below_all(data)
```

```{r}
df <- tibble(
  var1 = c(5,6,7,NA,9,10)
)

df %>% 
  impute_below_all()

df %>% 
  bind_shadow()

df %>% 
  bind_shadow() %>% 
  impute_below_all()
```

We can explore a number of missing for single variable. 

```{r}
aq_imp <- airquality %>% 
  bind_shadow() %>% 
  impute_below_all()

ggplot(aq_imp,
       aes( x= Ozone,
            fill = Ozone_NA))+
  geom_histogram()+
  facet_wrap(~Month)

ggplot(aq_imp,
       aes( x= Ozone,
            fill = Ozone_NA))+
  geom_histogram()+
  facet_wrap(~Solar.R_NA)
```

To visualize Missing values for two variables, the `add_label_missings` will do this for us.

```{r}
aq_imp <- airquality %>% 
  bind_shadow() %>% 
  add_label_missings() %>% 
  impute_below_all()

ggplot(aq_imp,
       aes(x = Ozone,
           y = Solar.R,
           color = any_missing))+
  geom_point()
```

## Impute data below range with nabular data

We want to keep track of values we imputed. If we don't, it is very difficult to assess how good the imputed values are.

We are going to practice imputing data and recreate visualizations in the previous set of exercises by imputing values below the range of the data.

This is a very useful way to help further explore missingness, and also provides the framework for imputing missing values.

First, we are going to impute the data below the range using `impute_below_all()`, and then visualize the data. We notice that although we can see where the missing values are in this instance, we need some way to track them. The track missing data programming pattern can help with this.

```{r}
# Impute the oceanbuoys data below the range using `impute_below`.
ocean_imp <- impute_below_all(oceanbuoys)

# Visualise the new missing values
ggplot(ocean_imp, 
       aes(x = wind_ew, y = air_temp_c)) +  
  geom_point()

# Impute and track data with `bind_shadow`, `impute_below_all`, and `add_label_shadow`
ocean_imp_track <- bind_shadow(oceanbuoys) %>% 
  impute_below_all() %>% 
  add_label_shadow()

# Look at the imputed values
ocean_imp_track

bind_shadow(oceanbuoys) %>% 
  impute_below_all() %>% 
  add_label_shadow()
```

## Visualize imputed values in a scatterplot

Now, let's recreate one of the previous plots we saw in chapter three that used `geom_miss_point()`.

To do this, we need to impute the data below the range of the data. This is a special kind of imputation to explore the data. This imputation will illustrate what we need to practice: how to track missing values. To impute the data below the range of the data, we use the function `impute_below_all()`.

```{r}
# Impute and track the missing values
ocean_imp_track <- bind_shadow(oceanbuoys) %>% 
  impute_below_all() %>% 
  add_label_shadow()

# Visualise the missingness in wind and air temperature, coloring missing air temp values with air_temp_c_NA
ggplot(ocean_imp_track, 
       aes(x = wind_ew, y = air_temp_c, color = air_temp_c_NA)) + 
  geom_point()

# Visualise humidity and air temp, coloring any missing cases using the variable any_missing
ggplot(ocean_imp_track, 
       aes(x = humidity, y = air_temp_c, color = any_missing)) +  
  geom_point()
```

## Create histogram of imputed data

Now that we can recreate the first visualization of geom_miss_point(), let's explore how we can apply this to other exploratory tasks.

One useful task is to evaluate the number of missings in a given variable using a histogram. We can do this using the ocean_imp_track dataset we created in the last exercise, which is loaded into this session.

```{r}
# Explore the values of air_temp_c, visualising the amount of missings with `air_temp_c_NA`.
p <- ggplot(ocean_imp_track, aes(x = air_temp_c, fill = air_temp_c_NA)) +  geom_histogram()

# Expore the missings in humidity using humidity_NA
p2 <- ggplot(ocean_imp_track,  aes(x = humidity, fill = humidity_NA)) + geom_histogram()

# Explore the missings in air_temp_c according to year, using `facet_wrap(~year)`.
p + facet_wrap(~year)

# Explore the missings in humidity according to year, using `facet_wrap(~year)`.
p2 + facet_wrap(~year)
```

## What makes a good imputation

- Understand good/bad imputations
- Evaluate missing values(e.g., mean, scale, spread)
- Using visualization
  - boxplots
  - scatterplots
  - histogram
  - many variables

Bad example is mean imputation. To examine ad imputation, we have

- `impute_mean(data$variable)`
- `impute_mean_if(data, is.numeric`
- `impute_mean_at(data, vars(var1, var2))`
- `impute_mean_all(data`

Similar to impute below, we can work on vectors, or some conditions. 

```{r}
aq_impute_mean <-  airquality %>% 
  bind_shadow(only_miss = T) %>% 
  impute_mean_all() %>% 
  add_label_shadow()

aq_impute_mean
```

When evaluating imputation, explore changes/similarities in

- the mean/median(boxplot)
- the spread
- the scale

```{r}
ggplot(aq_impute_mean,
       aes(x = Ozone_NA,
           y = Ozone))+
  geom_boxplot()
```

The spread imputation can be explored by scatter plot. When evaluating imputation,s explore changes/similarities in 

- __the spread( scatterplot)__

```{r}
ggplot(aq_impute_mean,
       aes( x = Ozone,
            y = Solar.R,
            col = any_missing))+
  geom_point()
```

## Evaluating bad imputations
In order to evaluate imputations, it helps to know what something bad looks like. To explore this, let's look at a typically bad imputation method: imputing using the mean value.

In this exercise we are going to explore how the mean imputation method works using a boxplot, using the `oceanbuoys` dataset.

```{r}
# Impute the mean value and track the imputations 
ocean_imp_mean <- bind_shadow(oceanbuoys) %>% 
  impute_mean_all() %>% 
  add_label_shadow()

# Explore the mean values in humidity in the imputed dataset
ggplot(ocean_imp_mean, 
       aes(x = humidity_NA, y = humidity)) + 
  geom_boxplot()

# Explore the values in air temperature in the imputed dataset
ggplot(ocean_imp_mean, 
       aes(x = air_temp_c_NA, y =  air_temp_c)) + 
  geom_boxplot()
```

## Evaluating imputations: The scale

While the mean imputation might not look so bad when we compare it using a boxplot, it is important to get a sense of the variation in the data. This is why it is important to explore how the scale and spread of imputed values changes compared to the data.

One way to evaluate the appropriateness of the scale of the imputations is to use a scatterplot to explore whether or not the values are appropriate.

```{r}
# Explore imputations in air temperature and humidity, coloring by the variable, any_missing
ggplot(ocean_imp_mean, 
       aes(x = air_temp_c, y = humidity, color = any_missing)) + 
  geom_point()

# Explore imputations in air temperature and humidity, coloring by the variable, any_missing, and faceting by year
ggplot(ocean_imp_mean, 
       aes(x = air_temp_c, y = humidity, color = any_missing)) + 
  geom_point() 
  facet_wrap(~year)
```

## Evaluating imputations: Across many variables
So far, we have covered ways to look at individual variables or pairs of variables and their imputed values. However, sometimes you want to look at imputations for many variables. To do this, you need to perform some data munging and re-arranging. This lesson covers how to perform this data wrangling, which can get a little bit hairy when considering its usage in `nabular` data. The function, `shadow_long()` gets the data into the right shape for these kinds of visualizations.

```{r}
# Gather the imputed data 
ocean_imp_mean_gather <- shadow_long(ocean_imp_mean,
                                     humidity,
                                     air_temp_c)
# Inspect the data
ocean_imp_mean_gather

# Explore the imputations in a histogram 
ggplot(ocean_imp_mean_gather, 
       aes(x = value, fill = value_NA)) + 
  geom_histogram(stat="count") + 
  facet_wrap(~variable)
```

## Performing imputations

- `simputation` package for imputation.
- We will focus on using linear model to impute values with `impute_lm`
- Assess new imputation
- Build many imputation models
- Compare imputations across different models and variables.

```{r}
df <- tibble::tribble(
  ~y, ~var1, ~var2,
  2.67, 2.43, 3.27,
  3.87, 3.55, 1.45,
  NA, 2.90, 1.49,
  5.21, 2.72, 1.84,
  NA, 4.29, 1.15
)

library(simputation)
df %>% 
  bind_shadow(only_miss = TRUE) %>% 
  add_label_shadow() %>% 
  impute_lm(y~var1+var2)
```

We will use `impute_lm` for `airquality` data.

```{r}
aq_imp_lm <- airquality %>% 
  bind_shadow() %>% 
  add_label_shadow() %>% 
  impute_lm(Solar.R~Wind+Temp+Month) %>% 
  impute_lm(Ozone~Wind+Temp+Month)

aq_imp_lm

aq_imp_lm %>% 
  ggplot(
    aes(x = Solar.R,
        y = Ozone,
        col = any_missing))+
      geom_point()

```

The important is to insert `bind_shadow()` and `add_label_shadow()` to detect missingness.

Another useful feature is conducts variants of lm application.

```{r}
aq_imp_small <- airquality %>%
  bind_shadow() %>%
  impute_lm(Ozone ~ Wind + Temp) %>%
  impute_lm(Solar.R ~ Wind + Temp) %>%
  add_label_shadow()

aq_imp_large <- airquality %>%
  bind_shadow() %>%
  impute_lm(Ozone ~ Wind + Temp + Month + Day) %>%
  impute_lm(Solar.R ~ Wind + Temp + Month + Day)  %>%
  add_label_shadow()
```

To compare models, we bind the above two variants.

```{r}
bound_models <- 
  bind_rows(small = aq_imp_small,
            large = aq_imp_large,
            .id   = "imp_model")
bound_models
```

We can then look at the values.

```{r}
ggplot(bound_models,
       aes(x = Ozone,
           y = Solar.R,
           col = any_missing))+
  geom_point()+
  facet_wrap(~imp_model)
```

To explore imputations across multiple variables and models, we gather selected variables.

```{r}
bound_models_gather <- bound_models %>%
  select(Ozone, Solar.R,
         any_missing, imp_model) %>%
  gather(key = "variable", value = "value",
         -any_missing, -imp_model)

bound_models_gather
```

```{r}
ggplot(bound_models_gather,
       aes(x = imp_model,
           y = value)) +
  geom_boxplot() + 
  facet_wrap(~variable)

bound_models_gather %>%
  filter(any_missing == "Missing") %>%
  ggplot(aes(x = imp_model,
             y = value)) +
  geom_boxplot() + 
  facet_wrap(~variable)
```

## Using simputation to impute data

There are many  imputation packages in R. We are going to focus on using the `simputation` package, which provides a simple, powerful interface into performing imputations.

Building a good imputation model is super important, but it is a complex topic - there is as much to building a good imputation model as there is for building a good statistical model. In this course, we are going to focus on how to evaluate imputations.

First, we are going to look at using `impute_lm()` function, which imputes values according to a specified linear model.

In this exercise, we are going to apply the previous assessment techniques to data with `impute_lm()`, and then build upon this imputation method in subsequent lessons.

```{r}
# Impute humidity and air temperature using wind_ew and wind_ns, and track missing values
ocean_imp_lm_wind <-  oceanbuoys%>% 
    bind_shadow() %>%
    impute_lm(air_temp_c ~ wind_ew + wind_ns) %>% 
    impute_lm(humidity ~ wind_ew + wind_ns) %>%
    add_label_shadow()
    
# Plot the imputed values for air_temp_c and humidity, colored by missingness
ggplot(ocean_imp_lm_wind, 
       aes(x = air_temp_c, y = humidity, color = any_missing)) + 
  geom_point()
```

## Evaluating and comparing imputations

When you build up an imputation model, it's a good idea to compare it to another method. In this lesson, we are going to compare the previously imputed dataset created using `impute_lm()` to the mean imputed dataset. Both of these datasets are included in this exercise as `ocean_imp_lm_wind` and `ocean_imp_mean` respectively.

```{r}
# Bind the models together 
bound_models <- bind_rows(mean = ocean_imp_mean,
                          lm_wind = ocean_imp_lm_wind,
                          .id = "imp_model")

# Inspect the values of air_temp and humidity as a scatterplot
ggplot(bound_models, 
       aes(x = air_temp_c, 
           y = humidity, 
           color = any_missing)) +
  geom_point() + 
  facet_wrap(~imp_model)
```

## Evaluating imputations (many models & variables)
When you build up an imputation model, it's a good idea to compare it to another method.

In this lesson, we are going to get you to add a final imputation model that contains an extra useful piece of information that helps explain some of the variation in the data. You are then going to compare the values, as previously done in the last lesson.

```{r}
# Build a model adding year to the outcome
ocean_imp_lm_wind_year <- bind_shadow(oceanbuoys) %>%
  impute_lm(air_temp_c ~ wind_ew + wind_ns + year) %>%
  impute_lm(humidity ~ wind_ew + wind_ns + year) %>%
  add_label_shadow()

# Bind the mean, lm_wind, and lm_wind_year models together
bound_models <- bind_rows(mean = ocean_imp_mean,
                          lm_wind = ocean_imp_lm_wind,
                          lm_wind_year = ocean_imp_lm_wind_year,
                          .id = "imp_model")

# Explore air_temp and humidity, coloring by any missings, and faceting by imputation model
ggplot(bound_models, aes(x = air_temp_c, y = humidity, color = any_missing)) + 
  geom_point() + facet_wrap(~imp_model)
```

```{r}
# Gather the data and inspect the distributions of the values
bound_models_gather <- bound_models %>%
  select(air_temp_c, humidity, any_missing, imp_model) %>%
  gather(key = "key", value = "value", -any_missing, -imp_model)

# Inspect the distribution for each variable, for each model
ggplot(bound_models_gather, 
       aes(x = imp_model, y = value, color = imp_model)) +
  geom_boxplot() + facet_wrap(~key, scales = "free_y")

# Inspect the imputed values
bound_models_gather %>%
  filter(any_missing == "Missing") %>%
  ggplot(aes(x = imp_model, y = value, color = imp_model)) +
  geom_boxplot() + facet_wrap(~key, scales = "free_y")
```

## Evaluating imputations and models

Our goal is to perform an analysis after imputing data.

1. Complete case analysis
2. Imputation using the imputed data from the last lesson.

```{r}
#1. complete case scinario
aq_cc <- airquality %>% 
  na.omit() %>% 
  bind_shadow() %>% 
  add_label_shadow()

#2. Imputation using the imputed data from the last lesson
aq_imp_lm <- bind_shadow(airquality) %>%
  add_label_shadow() %>%
  impute_lm(Ozone ~ Temp + Wind + Month + Day) %>%
  impute_lm(Solar.R ~ Temp + Wind + Month + Day)

 # 3. Bind the models together
bound_models <- bind_rows(cc = aq_cc,
                          imp_lm = aq_imp_lm,
                          .id = "imp_model")
```

After preparing the models, we fit a linear model separately.

```{r}

model_summary <- bound_models %>% 
  group_by(imp_model) %>%
  nest() %>%
  mutate(mod = map(data, 
                   ~lm(Temp ~ Ozone + Solar.R + Wind + Temp + Day + Month, data = .)),
         res = map(mod, residuals),
         pred = map(mod, predict),
         tidy = map(mod, broom::tidy))

model_summary
```

```{r}
model_summary %>% 
  select(imp_model,
         pred) %>%
  unnest() %>%
  ggplot(aes(x = pred,
             fill = imp_model)) +
  geom_histogram(position = "dodge")
```

## Combining and comparing many imputation models


To evaluate the different imputation methods, we need to put them into a single dataframe. Next, you will compare three different approaches to handling missing data using the dataset, oceanbuoys.

The first method is using only the completed cases and is loaded as ocean_cc.
The second method is imputing values using a linear model with predictions made using wind and is loaded as ocean_imp_lm_wind.
You will create the third imputed dataset, ocean_imp_lm_all, using a linear model and impute the variables `sea_temp_c`, `air_temp_c`, and `humidity` using the variables `wind_ew`, `wind_ns`, `year`, `latitude`, `longitude`.

You will then bind all of the datasets together (`ocean_cc`, `ocean_imp_lm_wind`, and `ocean_imp_lm_all`), calling it `bound_models`.

```{r}

# Create an imputed dataset using a linear models
ocean_imp_lm_all <- bind_shadow(oceanbuoys) %>%
  add_label_shadow() %>%
  impute_lm(sea_temp_c ~ wind_ew + wind_ns + year + latitude + longitude) %>%
  impute_lm(air_temp_c ~ wind_ew + wind_ns + year + latitude + longitude) %>%
  impute_lm(humidity ~ wind_ew + wind_ns + year + latitude + longitude)

# Bind the datasets
bound_models <- bind_rows(mean = ocean_imp_mean,
                          imp_lm_wind = ocean_imp_lm_wind,
                          imp_lm_all = ocean_imp_lm_all,
                          .id = "imp_model")
# Look at the models
bound_models
```

## Evaluating the different parameters in the model

We are imputing our data for a reason - we want to analyze the data!

In this example, we are interested in predicting sea temperature, so we will build a linear model predicting sea temperature.

We will fit this model to each of the datasets we created and then explore the coefficients in the data.

The objects from the previous lesson (`ocean_cc`, `ocean_imp_lm_wind`, `ocean_imp_lm_all`, and `bound_models`) are loaded into the workspace.

```{r}
# Create the model summary for each dataset
model_summary <- bound_models %>% 
  group_by(imp_model) %>%
  nest() %>%
  mutate(mod = map(data, ~lm(sea_temp_c ~ air_temp_c + humidity + year, data = .)),
         res = map(mod, residuals),
         pred = map(mod, predict),
         tidy = map(mod, broom::tidy))

# Explore the coefficients in the model
model_summary %>% 
    select(imp_model,tidy) %>%
	unnest()
best_model <- "imp_lm_all"
```




